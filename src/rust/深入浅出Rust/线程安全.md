# 线程安全
Rust不仅在没有自动垃圾回收（Garbage Collection）的条件下实现了内存安全，而且实现了线程安全。Rust编译器可以在编译阶段避免所有的数据竞争（Data Race）问题。

## 线程安全

### 什么是线程
线程是操作系统能够进行调度的最小单位，它是进程中的实际运作单位，每个进程至少包含一个线程。
多线程的优势有：
- 容易利用多核优势
- 比单线程反应更敏捷，比多进程资源共享更容易。

### 启动线程
Rust标准库中与线程相关的内容在`std::thread`模块中。Rust中的线程是对操作系统线程的直接封装。
创建线程的方法为：
```rs
use std::thread;
thread::spawn(move || {
  // 这里是新建线程的执行逻辑
});
```

默认情况下，新创建的子线程与原来的父线程是分离的关系。也就是说，子线程可以在父线程结束后继续存在，除非父线程是主线程。因为我们知道，如果一个进程的主线程也退出了，这个进程就会终止，其他所有的线程也会随之结束。

如果我们需要等待子线程执行结束，那么可以使用`join`方法：
```rs
use std::thread;
// child 的类型是 JoinHandle<T>,这个T是闭包的返回类型
let child = thread::spawn(move || {
  // 子线程的逻辑
});
// 父线程等待子线程结束
let res = child.join();
```

如果我们需要为子线程指定更多的参数信息，那么在创建的时候可以使用`Builder`模式：
```rs
use std::thread;
thread::Builder::new().name("child1".to_string()).spawn(move || {
  println!("Hello, world!");
});
```

`thread`模块还提供了下面几个工具函数。
1. `thread::sleep(dur:Duration)`
   使得当前线程等待一段时间继续执行。在等待的时间内，线程调度器会调度其他的线程来执行。
2. `thread::yield_now()`
   放弃当前线程的执行，要求线程调度器执行线程切换。
3. `thread::current()`
   获得当前的线程。
4. `thread::park()`
   暂停当前线程，进入等待状态。当`thread::Thread::unpark(&self)`方法被调用的时候，这个线程可以被恢复执行。
5. `thread::Thread::unpark(&self)`
   恢复一个线程的执行。

```rs
use std::thread;
use std::time::Duration;
fn main() {
  let t = thread::Builder::new()
    .name("child1".to_string())
    .spawn(move || {
      println!("enter child thread.");
      thread::park();
      println!("resume child thread");
    }).unwrap();
  println!("spawn a thread");
  thread::sleep(Duration::new(5,0));
  t.thread().unpark();
  t.join();
  println!("child thread finished");
}
```

### 免数据竞争
我们创建一个子线程，用它修改一个外部变量：
```rs
use std::thread;
fn main() {
  let mut health = 12;
  thread::spawn( || {
    health *= 2;
  });
  println!("{}", health);
}
```

编译，发生错误。错误信息为：
> error: closure may outlive the current function, but it borrows health, which is owned by the cu

`spawn`函数接受的参数是一个闭包。我们在闭包里面引用了函数体内的局部变量，而这个闭包是运行在另外一个线程上，编译器无法肯定局部变量`health`的生命周期一定大于闭包的生命周期，于是发生了错误。

把闭包加上`move`修饰。再次编译，可见编译错误已经消失。但是执行发现，变量`health`的值并未发生改变。
因为`health`是`Copy`类型，在遇到`move`型闭包的时候，闭包内的`health`实际上是一份新的复制，外面的变量并没有被真正修改。

如果我们使用的是非`Copy`类型，又会怎样呢？
```rs
use std::thread;
fn main() {
  let mut v : Vec<i32> = vec![];
  thread::spawn( || {
    v.push(1);
  });
  println!("{:?}", v);
}
```

编译，出现同样的错误。再次尝试给闭包加上`move`，还是出现编译错误：
> error: use of moved value: v


这个错误也好理解：既然我们已经把`v`移动到了闭包里面，那么它在本函数内就不能再继续使用了，因为其所有权已经移走了。

以上这几个试验全部失败了，那我们究竟怎样做才能让一个变量在不同线程中共享呢？
答案是：我们没有办法在多线程中直接读写普通的共享变量，除非使用Rust提供的线程安全相关的设施 。


根据数据竞争的定义，它的发生需要三个条件：
- 数据共享——有多个线程同时访问一份数据；
- 数据修改——至少存在一个线程对数据做修改；
- 没有同步——至少存在一个线程对数据的访问没有使用同步措施。

我们只要让这三个条件无法同时发生即可：
- 可以禁止数据共享，比如`actor-based concurrency`，多线程之间的通信仅靠发送消息来实现，而不是通过共享数据来实现；
- 可以禁止数据修改，比如`functional programming`，许多函数式编程语言严格限制了数据的可变性，而对共享性没有限制。

Rust允许存在可变变量，允许存在状态共享，同时也做到了完整无遗漏的 线程安全检查。因为Rust设计的一个核心思想就是“共享不可变，可变不共享”，然后再加上类型系统和合理的API设计，就可以保证共享数据在访问时一定使用了同步措施。


### Send & Sync
下面来简单讲解一下Rust是如何实现免疫数据竞争的。Rust线程安全背后的功臣是两个特殊的`trait`。
- `std::marker::Sync`
  如果类型`T`实现了`Sync`类型，那说明在不同的线程中使用`&T`访问同一个变量是安全的。
- `std::marker::Send`
  如果类型`T`实现了`Send`类型，那说明这个类型的变量在不同的线程中传递所有权是安全的。

Rust把类型根据`Sync`和`Send`做了分类。这样做起什么作用呢？当然是用在“泛型约束”中。Rust中所有跟多线程有关的API，会根据情况，要求类型必须满足`Sync`或者`Send`的约束。
你不可能随意在多线程之间共享变量，也不可能在使用多线程共享的时候忘记加锁。除非你使用`unsafe`，否则不可能写出存在“数据竞争”的代码来。

比如我们最常见的创建线程的函数`spawn`，它的完整函数签名是这样的：
```rs
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
  where F: FnOnce() -> T, F: Send + 'static, T: Send + 'static
```

我们需要注意的是，参数类型`F`有重要的约束条件`F: Send+'static, T: Send+'static`。但凡在线程之间传递所有权会发生安全问题的类型，都无法在这个参数中出现，否则就是编译错误。

另外，Rust对全局变量也有很多限制，你不可能简单地通过全局变量在多线程中随意共享状态。这样，编译器就会禁止掉可能有危险的线程间共享数据的行为。

线程安全是默认行为，大部分类型在单线程中是可以随意共享的，但是没办法直接在多线程中共享。


## 详解Send和Sync
### 什么是Send
根据定义：如果类型`T`实现了`Send trait`，那说明这个类型的变量在不同线程中传递所有权是安全的。
究竟具备什么特点的类型才满足`Send`约束？

如果一个类型可以安全地从一个线程`move`进入另一个线程，那它就是`Send`类型。
比如：普通的数字类型是`Send`，因为我们把数字`move`进入另一个线程之后，两个线程同时执行也不会造成什么安全问题。

更进一步，内部不包含引用的类型，都是`Send`。因为这样的类型跟外界没有什么关联，当它被`move`进入另一个线程之后，它所有的部分都跟原来的线程没什么关系了，不会出现并发访问的情况。比如`String`类型。

稍微复杂一点的，具有泛型参数的类型，是否满足`Send`大多是取决于参数类型是否满足`Send`。比如`Vec<T>`，只要我们能保证`T: Send`，那么`Vec<T>`肯定也是`Send`，把它`move`进入其他线程是没什么问题的。再比如`Cell<T>`、`RefCell<T>`、`Option<T>`、`Box<T>`，也都是这种情况。

还有一些类型，不论泛型参数是否满足`Send`，都是满足`Send`的。这种类型，可以看作一种“构造器”，把不满足`Send`条件的类型用它包起来，就变成了满足`Send`条件的类型。比如`Mutex<T>`就是这种。`Mutex<T>`这个类型实际上不关心它内部类型是怎样的，反正要访问内部数据，一定要调用`lock()`方法上锁，它的所有权在哪个线程中并不重要，所以把它`move`到其他线程也是没有问题的。

那么什么样的类型是`!Send`呢？典型的如`Rc<T>`类型。我们知道，`Rc`是引用计数指针，把`Rc`类型的变量`move`进入另外一个线程，只是其中一个引用计数指针`move`到了其他线程，这样会导致不同的线程中的`Rc`变量引用同一块数据，`Rc`内部实现没有做任何线程同步处理，这是肯定有问题的。所以标准库中早已指定`Rc`是`!Send`。当我们试图在线程边界传递这个类型的时候，就会出现编译错误。

但是相对的是，`Arc<T>`类型是符合`Send`的（当然需要`T: Send`）。为什么呢？因为`Arc`类型内部的引用计数用的是“原子计数”，对它进行增减操作，不会出现多线程数据竞争。所以，多个线程拥有指向同一个变量的`Arc`指针是可以接受的。


### 什么是Sync
`Sync`的定义是，如果类型`T`实现了`Sync trait`，那说明在不同的线程中使用`&T`访问同一个变量是安全的。

基本数字类型肯定是`Sync`。假如不同线程都拥有指向同一个`i32`类型的只读引用`&i32`，这是没什么问题的。因为这个类型引用只能读，不能写。多个线程读同一个整数是安全的

大部分具有泛型参数的类型是否满足`Sync`，很多都是取决于参数类型是否满足`Sync`。像`Box<T>`、`Vec<T>` `Option<T>`这种也是`Sync`的，只要其中的参数`T`是满足`Sync`的。

也有一些类型，不论泛型参数是否满足`Sync`，它都是满足`Sync`的。这种类型把不满足`Sync`条件的类型用它包起来，就变成了满足`Sync`条件的。`Mutex<T>`就是这种。多个线程同时拥有`&Mutex<T>`型引用，指向同一个变量是没问题的。

那么什么样的类型是`!Sync`呢？所有具有“内部可变性”而又没有多线程同步考虑的类型都不是`Sync`的。比如，`Cell<T`>和`RefCell<T>`就不能是`Sync`的。按照定义，如果我们多个线程中都持有指向同一个变量的`&Cell<T>`型指针，那么在多个线程中，都可以执行`Cell::set`方法来修改它里面的数据。而我们知道，这个方法在修改内部数据的时候，是没有考虑多线程同步问题的。所以，我们必须把它标记为`!Sync`。

还有一些特殊的类型，它们既具备内部可变性，又满足`Sync`约束，比如前面提到的`Mutex<T>`类型。为什么说`Mutex<T>`具备内部可变性？
这个类型可以通过不可变引用调用`lock()`方法，返回一个智能指针`MutexGuard<T>`类型，而这个智能指针有权修改内部数据。这个做法就跟`RefCell<T>`的`try_borrow_mut()`方法非常类似。区别只是：`Mutex::lock()`方法的实现，使用了操作系统提供的多线程同步机制，实现了线程同步，保证了异步安全；而`RefCell`的内部实现就是简单的普通数字加减操作。因此，`Mutex<T>`既具备内部可变性，又满足`Sync`约束。除了`Mutex<T>`，标准库中还有`RwLock<T>`、`AtomicBool`、`AtomicIsize`、`AtomicUsize`、`AtomicPtr`等类型，都提供了内部可变性，而且满足`Sync`约束。


### 自动推理
`Send`和`Sync`是`marker trait`。在Rust中，有一些`trait`是在`std::marker`模块中的特殊`trait`。它们有一个共同的特点，就是内部都没有任何的方法，它们只用于给类型做“标记”。在`std::marker`这个模块中的`trait`，都是给类型做标记的`trait`。每一种标记都将类型严格切分成了两个组。

我们可以从源码中的src/libcore/marker.rs中看到：
```rs
unsafe impl Send for .. { }
unsafe impl Sync for .. { }
```

这是一个临时的、特殊的语法，它的含义是：针对所有类型，默认实现了`Send/Sync`。使用了这种特殊语法的`trait`叫作`OIBIT（Opt-in builtin trait）`，后来改称为`Auto Trait`。

`Auto Trait`有一个重要特点，就是编译器允许用户不用手写`impl`，自动根据这个类型的成员“推理”出这个类型是否满足这个`trait`。

我们可以手动指定这个类型满足这个`trait`约束，也可以手动指定它不满足这个`trait`约束，但是手动指定的时候，一定要用`unsafe`关键字。
```rs
unsafe impl<T: ?Sized> !Send for *const T { }
unsafe impl<T: ?Sized> !Send for *mut T { }
unsafe impl<'a, T: Sync + ?Sized> Send for &'a T {}
unsafe impl<'a, T: Send + ?Sized> Send for &'a mut T {}
// 等等
```

使用`!Send`这种写法表示“取反”操作，这些类型就一定不满足`Send`约束。
标准库中把所有基本类型，以及标准库中定义的类型，都做了合适的`Send/Sync`标记。

同时，由于`Auto trait`这个机制的存在，绝大部分用户创建的自定义类型，本身都已经有了合理的`Send/Sync`标记，用户不需要手动修改它。只有一种情况例外：用户用了`unsafe`代码的时候，有些类型就很可能需要手动实现`Send/Sync`



## 状态共享
如何使用标准库安全地实现多线程访问共享变量。

### Arc
`Arc`是`Rc`的线程安全版本。它的全称是“Atomic reference counter”。注意第一个单词代表的是`atomic`而不是automatic。它强调的是“原子性”。它跟`Rc`最大的区别在于，引用计数用的是原子整数类型。
`Arc`使用方法示例如下：
```rs
use std::sync::Arc;
use std::thread;
fn main() {
  let numbers: Vec<_> = (0..100u32).collect();
  // 引用计数指针,指向一个 Vec
  let shared_numbers = Arc::new(numbers);
  // 循环创建 10 个线程
  for _ in 0..10 {
    // 复制引用计数指针,所有的 Arc 都指向同一个 Vec
    let child_numbers = shared_numbers.clone();
    // move修饰闭包,上面这个 Arc 指针被 move 进入了新线程中
    thread::spawn(move || {
      // 我们可以在新线程中使用 Arc,读取共享的那个 Vec
      let local_numbers = &child_numbers[..];
      // 继续使用 Vec 中的数据
    });
  }
}
```
如果我们把上面代码中的`Arc`改为`Rc`类型，是不能编译通过的
`Rc`类型内部的引用计数是普通整数类型，如果多个线程中分别同时持有指向同一块内存的`Rc`指针，是线程不安全的。这个错误是通过`spawn`函数的签名检查出来的。`spawn`要求闭包参数类型满足`Send`条件，闭包是没有显式`impl Send`或者`Sync`的，按照`auto trait`的推理规则，编译器会检查这个类型所有的成员是否满足`Send`或者`Sync`。目前这个闭包参数“捕获”了一个`Rc`类型，而`Rc`类型是不满足`Send`条件的，因此编译器推理出来这个闭包类型是不满足`Send`条件的，与`spawn`函数的约束条件发生了冲突。

查看源码我们可以发现，`Rc`和`Arc`这两个类型之间的区别，除了引用计数值的类型之外，主要如下：
```rs
unsafe impl<T: ?Sized + Sync + Send> Send for Arc<T> {}
unsafe impl<T: ?Sized + Sync + Send> Sync for Arc<T> {}

impl<T: ?Sized> !marker::Send for Rc<T> {}
impl<T: ?Sized> !marker::Sync for Rc<T> {}
```

编译器的推理过程为：`u32`是`Send`，得出`Unique<u32>`是`Send`，接着得出`Vec<u32>`是`Send`，然后得出`Arc<Vec<u32>>`是`Send`，最后得出闭包类型是`Send`。它能够符合`spawn`函数的签名约束，可以穿越线程边界。如果把共享变量类型变成`Cell<u32>`，那么`Arc<Cell<u32>>`依然是不符合条件的。因为`Cell`类型是不满足`Sync`的。


### Mutex
根据Rust的“共享不可变，可变不共享”原则，`Arc`既然提供了共享引用，就一定不能提供可变性。所以，`Arc`也是只读的，它对外API和`Rc`是一致的。如果我们要修改怎么办？同样需要“内部可变性”。
这种时候，我们需要用线程安全版本的“内部可变性”，如`Mutex`和`RwLock`。

下面我们用一个示例来演示一下`Arc`和`Mutex`配合。使用多线程修改共享变量：
```rs
use std::sync::Arc;
use std::sync::Mutex;
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
  let global = Arc::new(Mutex::new(0));
  let clone1 = global.clone();

  let thread1 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone1.lock().unwrap();
      *value += 1;
    }
  });

  let clone2 = global.clone();

  let thread2 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone2.lock().unwrap();
      *value -= 1;
    }
  });
  thread1.join().ok();
  thread2.join().ok();
  println!("final value: {:?}", global);
}
```

因为我们的闭包用了`move`关键字修饰，为了避免把`global`这个引用计数指针`move`进入闭包，所以在外面先提前复制一份，然后将复制出来的这个指针传入闭包中。这样两个线程就都拥有了指向同一个变量的`Arc`指针。

在这个程序中，我们使用两个线程修改同一个整数：一个线程对它进行多次加1，另一个线程对它进行多次减1。
这次，我们使用`Arc`来实现多线程之间的共享，使用`Mutex`来提供内部可变性。
每次需要修改的时候，我们需要调用`lock()`方法（或者`try_lock`）获得锁，然后才能对内部的数据进行读/写操作。
因为锁的存在，我们就可以保证整个“读/写”是一个完整的`transaction`。

对于`Mutex`类型，标准库中有：
```rs
unsafe impl<T: ?Sized + Send> Send for Mutex<T> { }
unsafe impl<T: ?Sized + Send> Sync for Mutex<T> { }
```
因此，`Arc<Mutex<isize>>`可以满足`Send`要求。

`Mutex::lock()`方法的返回类型是`LockResult<MutexGuard<T>>`：
```rs
pub fn lock(&self) -> LockResult<MutexGuard<T>>
```
其中`LockResult`就是`Result`类型的一个别名，是用于错误处理的：
```rs
type LockResult<Guard> = Result<Guard, PoisonError<Guard>>;
```

如果当前`Mutex`已经是“有毒”（`Poison`）的状态，它返回的就是错误。什么情况会导致`Mutex`有毒呢？当`Mutex`在锁住的同时发生了`panic`，就会将这个`Mutex`置为“有毒”的状态，以后再调用`lock()`都会失败。这个设计是为了`panic safety`而考虑的，主要就是考虑到在锁住的时候发生`panic`可能导致`Mutex`内部数据发生混乱。所以这个设计防止再次进入`Mutex`内部的时候访问了被破坏掉的数据内容。如果有需要的话，用户依然可以手动调用`PoisonError::into_inner()`方法获得内部数据。

而`MutexGuard`类型则是一个“智能指针”类型，它实现了`DerefMut`和`Deref`这两个`trait`，所以它可以被当作指向内部数据的普通指针使用。`MutexGuard`实现了一个析构函数，通过`RAII`手法，在析构函数中调用了`unlock()`方法解锁。因此，用户是不需要手动调用方法解锁的。

Rust的这个设计，优点不在于它“允许你做什么”，而在于它“不允许你做什么”。 
如果我们误用了`Rc<isize>`来实现线程之间的共享，就是编译错误。根据编译错误，我们将指针改为`Arc`类型，然后又会发现，它根本没有提供可变性。它的API只能共享读，根本没有写数据的方法存在。
此时，我们会想到加入内部可变性来允许多线程共享读写。如果我们使用了`Arc<RefCell<_>>`类型，依然是编译错误。因为`RefCell`类型不满足`Sync`。而`Arc<T>`需要内部的`T`参数必须满足`T: Sync`，才能使`Arc`满足`Sync`。把这些综合起来，我们可以推理出`Arc<RefCell<_>>`是`!Sync`。



### RwLock
`RwLock`就是“读写锁”。它跟`Mutex`很像，主要区别是对外暴露的API不一样。对`Mutex`内部的数据读写，`Mutex`都是调用同样的`lock`方法；而对`RwLock`内部的数据读写，它分别提供了一个成员方法`read/write`来做这个事情。其他方面基本和`Mutex`一致。示例如下：
```rs
use std::sync::Arc;
use std::sync::RwLock;
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
  let global = Arc::new(RwLock::new(0));
  let clone1 = global.clone();

  let thread1 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone1.write().unwrap();
      *value += 1;
  }
  });

  let clone2 = global.clone();

  let thread2 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone2.write().unwrap();
      *value -= 1;
    }
  });

  thread1.join().ok();
  thread2.join().ok();
  println!("final value: {:?}", global);
}
```

### Atomic
Rust标准库还为我们提供了一系列的“原子操作”数据类型，它们在`std::sync::atomic`模块里面。
它们都是符合`Sync`的，可以在多线程之间共享。
比如，我们有`AtomicIsize`类型，顾名思义，它对应的是`isize`类型的“线程安全”版本。
我们知道，普通的整数读取再写入，这种操作是非原子的。而原子整数的特点是，可以把“读取”“计算”“再写入”这样的操作编译为特殊的CPU指令，保证这个过程是原子操作。

我们来看一个示例：
```rs
use std::sync::Arc;
use std::sync::atomic::{AtomicIsize, Ordering};
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
  // Atomic 系列类型同样提供了线程安全版本的内部可变性
  let global = Arc::new(AtomicIsize::new(0));

  let clone1 = global.clone();

  let thread1 = thread::spawn(move|| {
    for _ in 0..COUNT {
      clone1.fetch_add(1, Ordering::SeqCst);
    }
  });

  let clone2 = global.clone();

  let thread2 = thread::spawn(move|| {
    for _ in 0..COUNT {
      clone2.fetch_sub(1, Ordering::SeqCst);
    }
  });

  thread1.join().ok();
  thread2.join().ok();
  println!("final value: {:?}", global);
}
```

我们还可以把这段代码改动一下：
```rs
use std::sync::Arc;
use std::sync::atomic::{AtomicIsize, Ordering};
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
  let global = Arc::new(AtomicIsize::new(0));

  let clone1 = global.clone();

  let thread1 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone1.load(Ordering::SeqCst);
      value += 1;
      clone1.store(value, Ordering::SeqCst);
    }
  });

  let clone2 = global.clone();

  let thread2 = thread::spawn(move|| {
    for _ in 0..COUNT {
      let mut value = clone2.load(Ordering::SeqCst);
      value -= 1;
      clone2.store(value, Ordering::SeqCst);
    }
  });

  thread1.join().ok();
  thread2.join().ok();
  println!("final value: {:?}", global);
}
```

与上一个版本相比，这段代码的区别在于：我们没有使用原子类型自己提供的`fetch_add` `fetch_sub`方法，而是使用了`load`把里面的值读取出来，然后执行加/减，操作完成后，再用`store`存储回去。编译程序我们看到，是可以编译通过的。再执行，出现了问题：这次的执行结果就不是保证为0了。

大家应该很容易看明白问题在哪里。原来的那种写法，“读取/计算/写入”是一个完整的“原子操作”，中间不可被打断，它是一个“事务”（transaction）。
而后面的写法把“读取”作为了一个“原子操作”，“写入”又作为了一个“原子操作”，把一个transaction分成了两段来执行。
上面的那个程序，其逻辑类似于“lock=>读数据=>加/减运算=>写数据=>unlock”。
下面的程序，其逻辑类似于“lock=>读数据=>unlock=>加/减运算=>lock=>写数据=>unlock”。
虽然每次读写共享变量都保证了唯一性，但逻辑还是错的。


### 死锁
哲学家就餐问题
```rs
use std::thread;
use std::sync::{Mutex, Arc};
use std::time::Duration;

struct Philosopher {
  name: String,
  left: usize,
  right: usize,
}

impl Philosopher {
  fn new(name: &str, left: usize, right: usize) -> Philosopher {
    Philosopher {
      name: name.to_string(),
      left: left,
      right: right,
    }
  }

  fn eat(&self, table: &Table) {
    let _left = table.forks[self.left].lock().unwrap();
    println!("{} take left fork.", self.name);
    
    thread::sleep(Duration::from_secs(2));

    let _right = table.forks[self.right].lock().unwrap();
    println!("{} take right fork.", self.name);

    thread::sleep(Duration::from_secs(1));
    println!("{} is done eating.", self.name);
  }
}

struct Table {
  forks: Vec<Mutex<()>>,
}

fn main() {
  let table = Arc::new(Table { forks: vec![
    Mutex::new(()),
    Mutex::new(()),
    Mutex::new(()),
    Mutex::new(()),
    Mutex::new(()),
  ]});

  let philosophers = vec![
    Philosopher::new("Judith Butler", 0, 1),
    Philosopher::new("Gilles Deleuze", 1, 2),
    Philosopher::new("Karl Marx", 2, 3),
    Philosopher::new("Emma Goldman", 3, 4),
    Philosopher::new("Michel Foucault", 4, 0),
  ];

  let handles: Vec<_> = philosophers.into_iter().map(|p| {
    let table = table.clone();
    thread::spawn(move || {
      p.eat(&table);
    })
  }).collect();

  for h in handles {
    h.join().unwrap();
  }
}
```

编译执行，我们可以发现，5个哲学家都拿到了他左边的那支筷子，而都在等待他右边的那支筷子。在没等到右边筷子的时候，每个人都不会释放自己已经拿到的那支筷子。于是，大家都进入了无限的等待之中，程序无法继续执行了。这就是“死锁”。

在Rust中，“死锁”问题是没有办法在编译阶段由静态检查来解决的。就像前面提到的“循环引用制造内存泄漏”一样，编译器无法通过静态检查来完全避免这个问题，需要程序员自己注意。


### Barrier
除了“锁”之外，Rust标准库还提供了一些其他线程之间的通信方式，比如`Barrier`等。`Barrier`是这样的一个类型，它使用一个整数做初始化，可以使得多个线程在某个点上一起等待，然后再继续执行。示例如下：
```rs
use std::sync::{Arc, Barrier};
use std::thread;

fn main() {
  let barrier = Arc::new(Barrier::new(10));

  let mut handlers = vec![];

  for _ in 0..10 {
    let c = barrier.clone();
    // The same messages will be printed together.
    // You will NOT see any interleaving.
    let t = thread::spawn(move|| {
      println!("before wait");
      c.wait();
      println!("after wait");
    });
    handlers.push(t);
  }
  for h in handlers {
    h.join().ok();
  }
}
```

这个程序创建了一个多个线程之间共享的`Barrier`，它的初始值是`10`。我们创建了`10`个子线程，每个子线程都有一个`Arc`指针指向了这个`Barrier`，并在子线程中调用了`Barrier::wait`方法。这些子线程执行到`wait`方法的时候，就开始进入等待状态，一直到`wait`方法被调用了`10`次，`10`个子线程都进入等待状态，此时`Barrier`就通知这些线程可以继续了。然后它们再开始执行下面的逻辑。



### Condvar
